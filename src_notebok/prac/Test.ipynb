{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27bbf7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window as W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "523cbf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"SparkSession\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc5c7b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.0.55:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>SparkSession</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x259d52f1840>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75994da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|  id| cd|\n",
      "+----+---+\n",
      "|  10|abc|\n",
      "|  20|abc|\n",
      "|NULL|abc|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(10,'abc'),(20,'abc'),(None,'abc')]\n",
    "schema = \"id int, cd string\"\n",
    "df = spark.createDataFrame(data = data, schema = schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27b1c8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|  id| cd|\n",
      "+----+---+\n",
      "|NULL|abc|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"id is null\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0c5acf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| id| cd|\n",
      "+---+---+\n",
      "| 10|abc|\n",
      "| 20|abc|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.id.isNotNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e4c8668",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"tbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e4d77924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------+------------------+-------+\n",
      "|count(1)|count(id)|count(cd)|count(DISTINCT cd)|sum(id)|\n",
      "+--------+---------+---------+------------------+-------+\n",
      "|       3|        2|        3|                 1|     30|\n",
      "+--------+---------+---------+------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = \"select count(*),count(id),count(cd),count(distinct cd),sum(id) from tbl\"\n",
    "spark.sql(sql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "94dae49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+-------+-------+\n",
      "|cnt|id_cnt|id_cnt|dcd_cnt|sum_cnt|\n",
      "+---+------+------+-------+-------+\n",
      "|  3|     2|     2|      1|     30|\n",
      "+---+------+------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg(F.count('*').alias('cnt'),\n",
    "       F.count('id').alias('id_cnt'),\n",
    "        F.count('id').alias('id_cnt'),\n",
    "        F.countDistinct('cd').alias('dcd_cnt'),\n",
    "        F.sum('id').alias('sum_cnt'),\n",
    "      \n",
    "      ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f3297ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|count(id)|\n",
      "+---------+\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = \"SELECT count(id) from tbl group by cd having count(id) = 1\"\n",
    "spark.sql(sql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ae2b17e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "| cd|cnt_id|\n",
      "+---+------+\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"cd\").agg(F.count('id').alias(\"cnt_id\")).filter(F.col('cnt_id') == 1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b3795607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- notes: string (nullable = true)\n",
      " |-- sales_date: string (nullable = true)\n",
      " |-- amount: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = [(10,'mango','2024-01-01',100),\n",
    "(10,'orange','2024-01-02',120),\n",
    "(11,'jeans','2024-01-03',200),\n",
    "(11,'jeans','2024-01-03',250),\n",
    "(11,'T-shirt','2024-01-04',200),\n",
    "(12,'Banana','2024-01-04',50)]\n",
    "data_schema = \"id int, notes string,sales_date string,amount int\"\n",
    "dataframe = spark.createDataFrame(data = dataset, schema = data_schema)\n",
    "dataframe.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5191b950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------+------+\n",
      "| id|  notes|sales_date|amount|\n",
      "+---+-------+----------+------+\n",
      "| 10|  mango|2024-01-01|   100|\n",
      "| 10| orange|2024-01-02|   120|\n",
      "| 11|  jeans|2024-01-03|   200|\n",
      "| 11|  jeans|2024-01-03|   250|\n",
      "| 11|T-shirt|2024-01-04|   200|\n",
      "| 12| Banana|2024-01-04|    50|\n",
      "+---+-------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c6d060eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------+------+\n",
      "| id|  notes|sales_date|amount|\n",
      "+---+-------+----------+------+\n",
      "| 10|  mango|2024-01-01|   100|\n",
      "| 10| orange|2024-01-02|   120|\n",
      "| 11|  jeans|2024-01-03|   200|\n",
      "| 11|  jeans|2024-01-03|   250|\n",
      "| 11|T-shirt|2024-01-04|   200|\n",
      "| 12| Banana|2024-01-04|    50|\n",
      "+---+-------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert sales_date data types\n",
    "from pyspark.sql.types import DateType\n",
    "dataframe2 = dataframe.withColumn(\"sales_date\",F.col('sales_date').cast(DateType()))\n",
    "dataframe2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "531b3ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  fetch the max sale amount for each date ID wise, also get sum of sales amount id wise --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "74530aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------+------+---------+---+\n",
      "| id| notes|sales_date|amount|DenseRank|Sum|\n",
      "+---+------+----------+------+---------+---+\n",
      "| 10|orange|2024-01-02|   120|        1|220|\n",
      "| 11| jeans|2024-01-03|   250|        1|650|\n",
      "| 12|Banana|2024-01-04|    50|        1| 50|\n",
      "+---+------+----------+------+---------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe2.select(\"id\",\"notes\",\"sales_date\",\"amount\").\\\n",
    "withColumn(\"DenseRank\",F.dense_rank().over(W.partitionBy(\"id\").orderBy(F.col(\"amount\").desc()))).\\\n",
    "withColumn(\"Sum\",F.sum('amount').over(W.partitionBy(\"id\").orderBy(F.col(\"amount\").asc()))).\\\n",
    "filter(F.col(\"DenseRank\") ==1).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c9eade00",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_data = dataframe2.select(\"id\",\"notes\",\"sales_date\",\"amount\").groupBy(\"id\").agg(\n",
    "    F.sum(\"amount\").alias(\"sum_amount\"),\n",
    "    F.max(\"amount\").alias(\"max_amont\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dfc625d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------+------+---+----------+---------+\n",
      "| id| notes|sales_date|amount| id|sum_amount|max_amont|\n",
      "+---+------+----------+------+---+----------+---------+\n",
      "| 10|orange|2024-01-02|   120| 10|       220|      120|\n",
      "| 11| jeans|2024-01-03|   250| 11|       650|      250|\n",
      "| 12|Banana|2024-01-04|    50| 12|        50|       50|\n",
      "+---+------+----------+------+---+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe2.join(agg_data,(dataframe2.id == agg_data.id) & (dataframe2.amount == agg_data.max_amont),\n",
    "                how=\"inner\" ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e946b268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------+------+\n",
      "| id|  notes|sales_date|amount|\n",
      "+---+-------+----------+------+\n",
      "| 10|  mango|2024-01-01|   100|\n",
      "| 10| orange|2024-01-02|   120|\n",
      "| 11|  jeans|2024-01-03|   200|\n",
      "| 11|  jeans|2024-01-03|   250|\n",
      "| 11|T-shirt|2024-01-04|   200|\n",
      "| 12| Banana|2024-01-04|    50|\n",
      "+---+-------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c1eb632a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-------------------+\n",
      "| id|               notes|               _str|\n",
      "+---+--------------------+-------------------+\n",
      "| 10|     [mango, orange]|       mango,orange|\n",
      "| 11|[jeans, jeans, T-...|jeans,jeans,T-shirt|\n",
      "| 12|            [Banana]|             Banana|\n",
      "+---+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe2.groupBy('id').agg(F.collect_list(\"notes\").alias(\"notes\")).withColumn(\"_str\",F.concat_ws(\",\", F.col(\"notes\"))).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
