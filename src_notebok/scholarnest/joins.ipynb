{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d90bbff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import spark_partition_id\n",
    "from pyspark.sql import functions as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5847828e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[2]\").appName(\"Vprople\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bb48124",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../data/propel_department*.csv\"\n",
    "department = spark.read.format(\"csv\").option(\"path\",filepath).option(\"inferSchema\",\"true\").option(\"header\",\"true\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d771c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+--------+\n",
      "|deptcode| deptname|location|\n",
      "+--------+---------+--------+\n",
      "|     101|       IT|   Noida|\n",
      "|     102|       HR|   Delhi|\n",
      "|     103|    Sales|   Noida|\n",
      "|     104|Marketing|   Noida|\n",
      "+--------+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "department.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dbbb56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------+-------------------+----------+-------------+-------+----------+--------+\n",
      "|empcode| empfname|emplname|              email|   phoneno|          job|manager|  hiredate|deptcode|\n",
      "+-------+---------+--------+-------------------+----------+-------------+-------+----------+--------+\n",
      "|      1|   Taukir|    Khan|   taukir@gmail.com|8010339935|Data Engineer|Santosh|2021-10-27|     101|\n",
      "|      2|   Saheba|  pathan|   saheba@gmail.com|3020339935|       DevOps|Santosh|2022-10-27|     101|\n",
      "|      3|   Zeenat|    khan|   zeenat@gmail.com|2015339935|       Tester|Santosh|2022-06-20|     101|\n",
      "|      5|     Sonu|    sona|     sonu@gmail.com|9115339935|     Staffing| Anajan|2020-07-20|     102|\n",
      "|      6|    Rahul|     cho|    rahul@gmail.com|8915339935|   advertiser|   Hema|2020-02-20|     103|\n",
      "|      7|    lavan|   reddy|    lavan@gmail.com|2115339935|      calling|   Hema|2021-02-20|     103|\n",
      "|      4|      Sab|   Saikh|   taukir@gmail.com|7015339935|    Recruiter| Anajan|2022-07-20|     102|\n",
      "|      8|Narayanam|   Desik|narayanam@gmail.com| 885339935|   Displaying|   Hema|2023-02-20|    NULL|\n",
      "+-------+---------+--------+-------------------+----------+-------------+-------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filepath = \"../data/vpropel_employee*.csv\"\n",
    "employee = spark.read.format(\"csv\").option(\"path\",filepath).option(\"inferSchema\",\"true\").option(\"header\",\"true\").load()\n",
    "employee.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad4c25ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------+----------+\n",
      "|empcode|  basic|additions|deductions|\n",
      "+-------+-------+---------+----------+\n",
      "|      1|15000.0|    500.0|       0.0|\n",
      "|      2|10000.0|    500.0|       0.0|\n",
      "|      3| 8000.0|    300.0|       0.0|\n",
      "|      4| 6000.0|    500.0|       0.0|\n",
      "|      5|10000.0|    500.0|       0.0|\n",
      "|      6| 5000.0|   2000.0|       0.0|\n",
      "|      7| 6000.0|   1500.0|     500.0|\n",
      "+-------+-------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filepath = \"../data/vpropel_salary*.csv\"\n",
    "salary = spark.read.format(\"csv\").option(\"path\",filepath).option(\"inferSchema\",\"true\").option(\"header\",\"true\").load()\n",
    "salary.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3a8545",
   "metadata": {},
   "source": [
    "## Ambiguty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b923fede",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (350273423.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [30]\u001b[1;36m\u001b[0m\n\u001b[1;33m    drop(department.deptcode).\\  # Drop similar colum or renamed before join\u001b[0m\n\u001b[1;37m                                                                            \n^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "employee.join(department, employee['deptcode'] == department['deptcode'], \"inner\").\\\n",
    "drop(department.deptcode).\\  # Drop similar colum or renamed before join\n",
    "select(\"empfname\",\"deptname\",\"deptcode\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55745804",
   "metadata": {},
   "source": [
    "# 1: find out duplicate email address from emplyee table;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "943d6397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n",
      "|           email|count|\n",
      "+----------------+-----+\n",
      "|taukir@gmail.com|    2|\n",
      "+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee.groupBy(\"email\").count().where(\"count > 1\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa26f2b",
   "metadata": {},
   "source": [
    "## Display DeptName, and number of employee in each department."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f44f89e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|deptname|count|\n",
      "+--------+-----+\n",
      "|   Sales|    2|\n",
      "|      HR|    2|\n",
      "|      IT|    3|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee.join(department, employee['deptcode'] == department['deptcode'], \"inner\").\\\n",
    "groupBy(sf.col(\"deptname\")).count().alias(\"num_employees\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c475f62b",
   "metadata": {},
   "source": [
    "## find the department_name and  total spend salary on employee  by each department."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fd563af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+\n",
      "|deptname|batch_bal|\n",
      "+--------+---------+\n",
      "|   Sales|  14000.0|\n",
      "|      HR|  17000.0|\n",
      "|      IT|  34300.0|\n",
      "+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee.join(department, employee['deptcode'] == department['deptcode']).\\\n",
    "join(salary,employee['empcode'] == salary['empcode']).\\\n",
    "groupBy(sf.col(\"deptname\")).agg(sf.sum(sf.expr(\"basic + additions - deductions\")).alias(\"batch_bal\")).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
