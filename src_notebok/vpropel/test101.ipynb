{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22e00ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from  pyspark.sql import functions as FS\n",
    "from  pyspark.sql import Window  as WN\n",
    "from pyspark.sql import types as TYP\n",
    "\n",
    "from pyspark.conf import SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d61aebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Test\").config(\"spark.driver.memory\",\"1G\").getOrCreate()\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", 104857600)\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7efdfa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sparkContext.getConf().getAll()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62708d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.0.55:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x18a88131330>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75cc6777",
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_date = [\n",
    "(1,'JOE',85000,1),\n",
    "(2,'Henry',80000,2),\n",
    "(3,'Sam',60000,2),\n",
    "(4,'Max',90000,1),\n",
    "(5,'Janet',69000,1),\n",
    "(6,'Randy',85000,1),\n",
    "(7,'Will',70000,1)\n",
    "]\n",
    "emp_schema = [ 'ID', 'NAME', 'SALARY','DEPARTMENTID']\n",
    "dept_data = [\n",
    "(1,'IT'),\n",
    "(2,'Sales')\n",
    "]\n",
    "dept_schema = [ 'ID', 'NAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1633e016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+------------+\n",
      "| ID| NAME|SALARY|DEPARTMENTID|\n",
      "+---+-----+------+------------+\n",
      "|  1|  JOE| 85000|           1|\n",
      "|  2|Henry| 80000|           2|\n",
      "|  3|  Sam| 60000|           2|\n",
      "|  4|  Max| 90000|           1|\n",
      "|  5|Janet| 69000|           1|\n",
      "|  6|Randy| 85000|           1|\n",
      "|  7| Will| 70000|           1|\n",
      "+---+-----+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df = spark.createDataFrame(data =employee_date,schema = emp_schema)\n",
    "emp_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc69d09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| ID| NAME|\n",
      "+---+-----+\n",
      "|  1|   IT|\n",
      "|  2|Sales|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dept_df = spark.createDataFrame(data =dept_data,schema = dept_schema)\n",
    "dept_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf2ff930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+------+-------+-----+\n",
      "|emp_id| NAME|SALARY|dept_id|  dpt|\n",
      "+------+-----+------+-------+-----+\n",
      "|     1|  JOE| 85000|      1|   IT|\n",
      "|     4|  Max| 90000|      1|   IT|\n",
      "|     5|Janet| 69000|      1|   IT|\n",
      "|     6|Randy| 85000|      1|   IT|\n",
      "|     7| Will| 70000|      1|   IT|\n",
      "|     2|Henry| 80000|      2|Sales|\n",
      "|     3|  Sam| 60000|      2|Sales|\n",
      "+------+-----+------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "join_data = emp_df.join(dept_df, emp_df.DEPARTMENTID ==dept_df.ID).\\\n",
    "select(emp_df.ID.alias(\"emp_id\"),emp_df.NAME,emp_df.SALARY,dept_df.ID.alias(\"dept_id\"),dept_df.NAME.alias(\"dpt\"))\n",
    "join_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a1d7838",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnk_data = join_data.withColumn(\"rnk\",FS.dense_rank().over(WN.partitionBy('dept_id').orderBy(FS.desc('SALARY'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6bd0bc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+------+-------+-----+---+\n",
      "|emp_id| NAME|SALARY|dept_id|  dpt|rnk|\n",
      "+------+-----+------+-------+-----+---+\n",
      "|     4|  Max| 90000|      1|   IT|  1|\n",
      "|     2|Henry| 80000|      2|Sales|  1|\n",
      "+------+-----+------+-------+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnk_data.filter(\"rnk == 1\").select(\"*\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e23f3b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+------+-------+-----+\n",
      "|emp_id| NAME|SALARY|dept_id|  dpt|\n",
      "+------+-----+------+-------+-----+\n",
      "|     1|  JOE| 85000|      1|   IT|\n",
      "|     4|  Max| 90000|      1|   IT|\n",
      "|     5|Janet| 69000|      1|   IT|\n",
      "|     6|Randy| 85000|      1|   IT|\n",
      "|     7| Will| 70000|      1|   IT|\n",
      "|     2|Henry| 80000|      2|Sales|\n",
      "|     3|  Sam| 60000|      2|Sales|\n",
      "+------+-----+------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Second Method\n",
    "join_data = emp_df.join(dept_df, emp_df.DEPARTMENTID ==dept_df.ID).\\\n",
    "select(emp_df.ID.alias(\"emp_id\"),emp_df.NAME,emp_df.SALARY,dept_df.ID.alias(\"dept_id\"),dept_df.NAME.alias(\"dpt\"))\n",
    "join_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "549cdc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+\n",
      "|DEPARTMENTID|MAX_SAL|\n",
      "+------------+-------+\n",
      "|           1|  90000|\n",
      "|           2|  80000|\n",
      "+------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_sal_data = emp_df.groupBy(\"DEPARTMENTID\").agg(FS.max(\"SALARY\").alias(\"MAX_SAL\"))\n",
    "max_sal_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da5e278d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+------+-----+\n",
      "|emp_id| NAME|SALARY|  dpt|\n",
      "+------+-----+------+-----+\n",
      "|     4|  Max| 90000|   IT|\n",
      "|     2|Henry| 80000|Sales|\n",
      "+------+-----+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "join_data.join(FS.broadcast(max_sal_data),join_data.dept_id == max_sal_data.DEPARTMENTID,\"inner\").\\\n",
    "filter(\"SALARY == MAX_SAL\").select(\"emp_id\",\"NAME\",\"SALARY\",\"dpt\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8c586cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 'y', '1': '2', 't': 'y'}\n"
     ]
    }
   ],
   "source": [
    "data_dict = [\n",
    "{ \"x\": \"y\"},\n",
    "{ \"1\": \"2\"},\n",
    "{ \"t\": \"y\"}\n",
    "]\n",
    "\n",
    "# Output: {\"x\": \"y\", \"1\": \"2\", \"t\": \"y\"}\n",
    "temp_dict = {}\n",
    "for row in data_dict:\n",
    "    for key,val in row.items():\n",
    "        temp_dict[key] = val\n",
    "print(temp_dict)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b40a8290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|amount| id|\n",
      "+------+---+\n",
      "|    10|abc|\n",
      "|    20|def|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = [\n",
    "    {\"id\":\"abc\",\"amount\":10},\n",
    "    {\"id\":\"def\",\"amount\":20}\n",
    "]\n",
    "df = spark.createDataFrame(dataset)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bed8dc1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amount': 10, 'id': 'abc'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.collect()[0].asDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8574694f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\"amount\":10,\"id\":\"abc\"}', '{\"amount\":20,\"id\":\"def\"}']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toJSON().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf32ada2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 20]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = df.rdd.map(lambda x: x[0]).collect()\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9bb60522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 20]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amount = df.rdd.map(lambda x: x[0]).collect()\n",
    "amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "090097e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [10, 20], 'amount2': [10, 20]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.withColumn(\"ids\",FS.lit(ids)).withColumn(\"amount2\",FS.lit(amount)).drop(\"amount\",\"id\").collect()[0].asDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b7e250d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|   month|sales|\n",
      "+--------+-----+\n",
      "|Apr-2020|10000|\n",
      "|May-2020|12000|\n",
      "|Jun-2020|11400|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = [\n",
    "    {\"month\":\"Apr-2020\",\"sales\":10000},\n",
    "     {\"month\":\"May-2020\",\"sales\":12000},\n",
    "     {\"month\":\"Jun-2020\",\"sales\":11400},\n",
    "]\n",
    "sale_df = spark.createDataFrame(dataset)\n",
    "sale_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "220b08d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_date_format(date_str):\n",
    "    from datetime import datetime\n",
    "    l1 = date_str.split(\"-\")\n",
    "    date_str1 = f\"{l1[-1]}-{l1[0]}-01\"\n",
    "    return  datetime.strptime(date_str1,\"%Y-%b-%d\")\n",
    "\n",
    "create_date_format_udf = FS.udf(lambda x: create_date_format(x),TYP.DateType())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d7083c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+----------+-------------+------------+\n",
      "|   month|sales|     date1|previous_sale|sales_growtn|\n",
      "+--------+-----+----------+-------------+------------+\n",
      "|Apr-2020|10000|2020-04-01|         NULL|        NULL|\n",
      "|May-2020|12000|2020-05-01|        10000|        20.0|\n",
      "|Jun-2020|11400|2020-06-01|        12000|        -5.0|\n",
      "+--------+-----+----------+-------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sale_df.withColumn(\"date1\",create_date_format_udf(\"month\")).\\\n",
    "withColumn(\"previous_sale\",FS.lag(FS.col('sales')).over((WN.partitionBy().orderBy(\"date1\")))).\\\n",
    "withColumn(\"sales_growtn\",FS.when(FS.col('previous_sale') == None,'NA').\\\n",
    "           otherwise((FS.col(\"sales\") - FS.col('previous_sale'))/FS.col(\"previous_sale\") * 100)).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e9af4369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "|dno|                 eno|\n",
      "+---+--------------------+\n",
      "|  1|  [1, 2, 3, 4, 5, 6]|\n",
      "|  2|[7, 8, 9, 10, 11,...|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, [1,2,3,4,5,6]), (2, [7,8,9,10,11,12,13])]\n",
    "df_arr = spark.createDataFrame(data, [\"dno\", \"eno\"])\n",
    "df_arr.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bb9f3e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cricket_data = [(\"Virat Kohli\", 85, 100, 75),\n",
    "        (\"Steve Smith\", 90, 105, 80),\n",
    "        (\"Kane Williamson\", 88, 95, 70)]\n",
    "columns = [\"Player\", \"Match1\", \"Match2\", \"Match3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8316dfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------+------+------+\n",
      "|         Player|Match1|Match2|Match3|\n",
      "+---------------+------+------+------+\n",
      "|    Virat Kohli|    85|   100|    75|\n",
      "|    Steve Smith|    90|   105|    80|\n",
      "|Kane Williamson|    88|    95|    70|\n",
      "+---------------+------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cricket_df = spark.createDataFrame(data = cricket_data,schema = columns)\n",
    "cricket_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a05f8fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------+-----+\n",
      "|         Player|   Match|Score|\n",
      "+---------------+--------+-----+\n",
      "|    Virat Kohli|Match111|   85|\n",
      "|    Virat Kohli|  Match2|  100|\n",
      "|    Virat Kohli|  Match3|   75|\n",
      "|    Steve Smith|Match111|   90|\n",
      "|    Steve Smith|  Match2|  105|\n",
      "|    Steve Smith|  Match3|   80|\n",
      "|Kane Williamson|Match111|   88|\n",
      "|Kane Williamson|  Match2|   95|\n",
      "|Kane Williamson|  Match3|   70|\n",
      "+---------------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stack_expr = \"stack(3,'Match111', Match1,'Match2',Match2,'Match3',Match3) as (Match, Score)\"\n",
    "stack_df1 = cricket_df.select(\"Player\",FS.expr(stack_expr))\n",
    "stack_df1.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
