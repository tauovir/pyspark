{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c1b2452",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window as W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "939a4102",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DateType,StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2e9bbcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beaf04b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"epam\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d914f4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d3e4d8",
   "metadata": {},
   "source": [
    "**GroupByKey**:<br>\n",
    "groupByKey() operates on Pair RDDs and is used to group all the values related to a given key.<br>\n",
    "groupByKey() always results in Hash-Partitioned RDDs.\n",
    "\n",
    "**ReduceByKey**:<br>\n",
    "ReduceByKey(function) - When called on a dataset of (K, V) pairs, returns a dataset of (K, V) pairs where the values for each key are aggregated using the given reduce function\n",
    "\n",
    "**USe Case**:<br>\n",
    "**GroupByKey:** is typically used when we need to group data by key and process all the values associated with each key together. It is common in scenarios like word count or grouping data for further analysis.<br>\n",
    "**ReduceByKey:** is used when we need to perform aggregations or computations on grouped values based on their keys. It is suitable for scenarios like calculating sum, average, maximum, or minimum values for each key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "45d5a894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, <pyspark.resultiterable.ResultIterable at 0x1f840e641f0>),\n",
       " (2, <pyspark.resultiterable.ResultIterable at 0x1f840e64340>)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([(1, 'apple'), (2, 'banana'), (1, 'cherry')])\n",
    "\n",
    "grouped_rdd = rdd.groupByKey()\n",
    "\n",
    "# Result: [(1, ['apple', 'cherry']), (2, ['banana'])]\n",
    "grouped_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df1bb91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 6), (2, 3)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([(1, 2), (2, 3), (1, 4)])\n",
    "summed_rdd = rdd.reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "# Result: [(1, 6), (2, 3)]\n",
    "summed_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60df1993",
   "metadata": {},
   "source": [
    "### Map VS FlatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "489a3d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', '2', '3'], ['4', '5', '6'], ['7', '8', '9']]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array1d = sc.parallelize ((\"1,2,3\", \"4,5,6\", \"7,8,9\"))  \n",
    "x =array1d.map(lambda x: x.split(\",\"))\n",
    "x.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5e21e643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3', '4', '5', '6', '7', '8', '9']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_flat = sc.parallelize ((\"1,2,3\", \"4,5,6\", \"7,8,9\"))  \n",
    "flat_rdd =array1d.flatMap(lambda x: x.split(\",\"))\n",
    "flat_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d9721c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
